{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/kbxw3yp15078rb4blsyr1khw0000gn/T/ipykernel_75228/3110156780.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  timekeeping_df['date'] = pd.to_datetime(timekeeping_df['date'])\n",
      "/var/folders/0b/kbxw3yp15078rb4blsyr1khw0000gn/T/ipykernel_75228/3110156780.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n",
      "/var/folders/0b/kbxw3yp15078rb4blsyr1khw0000gn/T/ipykernel_75228/3110156780.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n",
      "/var/folders/0b/kbxw3yp15078rb4blsyr1khw0000gn/T/ipykernel_75228/3110156780.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n",
      "/var/folders/0b/kbxw3yp15078rb4blsyr1khw0000gn/T/ipykernel_75228/3110156780.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n",
      "/var/folders/0b/kbxw3yp15078rb4blsyr1khw0000gn/T/ipykernel_75228/3110156780.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n",
      "/var/folders/0b/kbxw3yp15078rb4blsyr1khw0000gn/T/ipykernel_75228/3110156780.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared data shape: (138, 23)\n",
      "\n",
      "Sample of prepared data:\n",
      "   employee_id  year                  department Location Supervisor  \\\n",
      "0           40  2024              ADMINISTRATION       SD     Joseph   \n",
      "1          214  2024               IT DEPARTMENT       SD       Mary   \n",
      "2          238  2021  LOGISTICS AND DISTRIBUTION       SD      Linda   \n",
      "3          238  2022  LOGISTICS AND DISTRIBUTION       SD      Linda   \n",
      "4          238  2023  LOGISTICS AND DISTRIBUTION       SD      Linda   \n",
      "\n",
      "   days_worked  avg_daily_hours  total_hours  max_daily_hours  \\\n",
      "0           37         7.956306   294.383333         8.950000   \n",
      "1            4         6.579167    26.316667         8.116667   \n",
      "2           11         7.657576    84.233333         8.083333   \n",
      "3           45         7.755556   349.000000         8.733333   \n",
      "4           53         7.630503   404.416667         8.033333   \n",
      "\n",
      "   min_daily_hours  ...  pay_rate  first_year  tenure  previous_pay_rate  \\\n",
      "0         7.716667  ...      16.0        2024       1               16.0   \n",
      "1         2.100000  ...      29.0        2024       1               29.0   \n",
      "2         5.450000  ...      16.5        2021       1               16.5   \n",
      "3         4.316667  ...       0.0        2021       2               16.5   \n",
      "4         4.100000  ...       0.0        2021       3                0.0   \n",
      "\n",
      "   pay_rate_change  pay_rate_change_pct  has_payroll_data  department_encoded  \\\n",
      "0              0.0                  0.0              True                   0   \n",
      "1              0.0                  0.0              True                   2   \n",
      "2              0.0                  0.0              True                   3   \n",
      "3            -16.5               -100.0              True                   3   \n",
      "4              0.0                  0.0              True                   3   \n",
      "\n",
      "   location_encoded  supervisor_encoded  \n",
      "0                 1                  11  \n",
      "1                 1                  15  \n",
      "2                 1                  13  \n",
      "3                 1                  13  \n",
      "4                 1                  13  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "Features available for ML:\n",
      "- employee_id\n",
      "- year\n",
      "- department\n",
      "- Location\n",
      "- Supervisor\n",
      "- days_worked\n",
      "- avg_daily_hours\n",
      "- total_hours\n",
      "- max_daily_hours\n",
      "- min_daily_hours\n",
      "- std_daily_hours\n",
      "- missing_punches\n",
      "- overtime_days\n",
      "- pay_rate\n",
      "- first_year\n",
      "- tenure\n",
      "- previous_pay_rate\n",
      "- pay_rate_change\n",
      "- pay_rate_change_pct\n",
      "- has_payroll_data\n",
      "- department_encoded\n",
      "- location_encoded\n",
      "- supervisor_encoded\n",
      "\n",
      "Prepared data saved to 'employee_data_prepared_for_ml.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load datasets\n",
    "def load_and_prepare_data():\n",
    "    # Load timekeeping data\n",
    "    timekeeping_df = pd.read_csv('sample_timekeeping.csv')\n",
    "    \n",
    "    # Load payroll data\n",
    "    payroll_df = pd.read_csv('sample_payroll.csv')\n",
    "    \n",
    "    # Ensure proper data types\n",
    "    payroll_df['employee_id'] = payroll_df['employee_id'].astype(int)\n",
    "    payroll_df['year'] = payroll_df['year'].astype(int)\n",
    "    payroll_df['pay_rate'] = payroll_df['pay_rate'].astype(float)\n",
    "    \n",
    "    # Convert date column to datetime and extract year\n",
    "    timekeeping_df['date'] = pd.to_datetime(timekeeping_df['date'])\n",
    "    timekeeping_df['year'] = timekeeping_df['date'].dt.year\n",
    "    \n",
    "    return timekeeping_df, payroll_df\n",
    "\n",
    "# Process time punches to calculate work duration\n",
    "def process_time_punches(df):\n",
    "    # Convert punch times to datetime\n",
    "    time_columns = ['punchin1', 'punchout1', 'punchin2', 'punchout2', 'punchin3', 'punchout3']\n",
    "    \n",
    "    for col in time_columns:\n",
    "        # Handle missing values\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    \n",
    "    # Calculate duration for each punch pair (in hours)\n",
    "    df['duration1'] = (df['punchout1'] - df['punchin1']).dt.total_seconds() / 3600\n",
    "    df['duration2'] = (df['punchout2'] - df['punchin2']).dt.total_seconds() / 3600\n",
    "    df['duration3'] = (df['punchout3'] - df['punchin3']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Replace negative or NaN values with 0\n",
    "    duration_cols = ['duration1', 'duration2', 'duration3']\n",
    "    for col in duration_cols:\n",
    "        df[col] = df[col].fillna(0)\n",
    "        df[col] = np.where(df[col] < 0, 0, df[col])\n",
    "    \n",
    "    # Calculate total daily hours\n",
    "    df['daily_hours'] = df['duration1'] + df['duration2'] + df['duration3']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create employee-year features\n",
    "def create_employee_year_features(df):\n",
    "    # Group by employee_id and year\n",
    "    grouped = df.groupby(['employee_id', 'year', 'department', 'Location', 'Supervisor'])\n",
    "    \n",
    "    # Create features\n",
    "    employee_year_features = grouped.agg(\n",
    "        days_worked=('date', 'count'),\n",
    "        avg_daily_hours=('daily_hours', 'mean'),\n",
    "        total_hours=('daily_hours', 'sum'),\n",
    "        max_daily_hours=('daily_hours', 'max'),\n",
    "        min_daily_hours=('daily_hours', lambda x: x[x > 0].min() if len(x[x > 0]) > 0 else 0),\n",
    "        std_daily_hours=('daily_hours', 'std'),\n",
    "        missing_punches=('daily_hours', lambda x: sum(x == 0)),\n",
    "        overtime_days=('daily_hours', lambda x: sum(x > 8))\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Fill NaN values with 0 for std_daily_hours\n",
    "    employee_year_features['std_daily_hours'] = employee_year_features['std_daily_hours'].fillna(0)\n",
    "    \n",
    "    return employee_year_features\n",
    "\n",
    "# Calculate tenure features\n",
    "def add_tenure_features(df):\n",
    "    # Get the earliest year for each employee\n",
    "    employee_first_year = df.groupby('employee_id')['year'].min().reset_index()\n",
    "    employee_first_year.rename(columns={'year': 'first_year'}, inplace=True)\n",
    "    \n",
    "    # Merge to get first year for each employee\n",
    "    df = pd.merge(df, employee_first_year, on='employee_id')\n",
    "    \n",
    "    # Calculate tenure\n",
    "    df['tenure'] = df['year'] - df['first_year'] + 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add pay rate change features\n",
    "def add_pay_rate_changes(df):\n",
    "    # Create a dataframe with previous year's pay rate\n",
    "    prev_pay = df[['employee_id', 'year', 'pay_rate']].copy()\n",
    "    prev_pay['year'] = prev_pay['year'] + 1\n",
    "    prev_pay.rename(columns={'pay_rate': 'previous_pay_rate'}, inplace=True)\n",
    "    \n",
    "    # Merge with current data\n",
    "    df = pd.merge(df, prev_pay, on=['employee_id', 'year'], how='left')\n",
    "    \n",
    "    # Calculate pay rate change\n",
    "    df['previous_pay_rate'] = df['previous_pay_rate'].fillna(df['pay_rate'])  # For first year\n",
    "    df['pay_rate_change'] = df['pay_rate'] - df['previous_pay_rate']\n",
    "    \n",
    "    # Avoid division by zero or null errors\n",
    "    df['pay_rate_change_pct'] = np.where(\n",
    "        df['previous_pay_rate'] > 0,\n",
    "        (df['pay_rate_change'] / df['previous_pay_rate']) * 100,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Create a flag for missing payroll data\n",
    "    df['has_payroll_data'] = ~pd.isnull(df['pay_rate']) | (df['pay_rate'] > 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Main function to execute the pipeline\n",
    "def prepare_data_for_ml():\n",
    "    # Load data\n",
    "    timekeeping_df, payroll_df = load_and_prepare_data()\n",
    "    \n",
    "    # Process time punches\n",
    "    timekeeping_df = process_time_punches(timekeeping_df)\n",
    "    \n",
    "    # Create employee-year features\n",
    "    employee_year_features = create_employee_year_features(timekeeping_df)\n",
    "    \n",
    "    # Merge with payroll data - using LEFT join to keep all employee-year records\n",
    "    merged_df = pd.merge(employee_year_features, payroll_df, \n",
    "                         on=['employee_id', 'year'], how='left')\n",
    "    \n",
    "    # Handle missing pay rates\n",
    "    merged_df['pay_rate'] = merged_df['pay_rate'].fillna(0)  # Fill missing pay rates with 0 or another strategy\n",
    "    \n",
    "    # Add tenure features\n",
    "    merged_df = add_tenure_features(merged_df)\n",
    "    \n",
    "    # Add pay rate change features\n",
    "    merged_df = add_pay_rate_changes(merged_df)\n",
    "    \n",
    "    # Optional: Create categorical features\n",
    "    merged_df['department_encoded'] = merged_df['department'].astype('category').cat.codes\n",
    "    merged_df['location_encoded'] = merged_df['Location'].astype('category').cat.codes\n",
    "    merged_df['supervisor_encoded'] = merged_df['Supervisor'].astype('category').cat.codes\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Execute the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    prepared_data = prepare_data_for_ml()\n",
    "    \n",
    "    # Display summary of prepared data\n",
    "    print(f\"Prepared data shape: {prepared_data.shape}\")\n",
    "    print(\"\\nSample of prepared data:\")\n",
    "    print(prepared_data.head())\n",
    "    \n",
    "    # Show feature list\n",
    "    print(\"\\nFeatures available for ML:\")\n",
    "    for column in prepared_data.columns:\n",
    "        print(f\"- {column}\")\n",
    "    \n",
    "    # Save prepared data\n",
    "    prepared_data.to_csv('employee_data_prepared_for_ml.csv', index=False)\n",
    "    print(\"\\nPrepared data saved to 'employee_data_prepared_for_ml.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
